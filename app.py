import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import time
import re
import traceback

# ==========================================
# 1. ãƒšãƒ¼ã‚¹è§£æãƒ»å±•é–‹äºˆæƒ³ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================

def calculate_early_pace_speed(row):
    """ å‰åŠ3F(600m)ã®ã‚¿ã‚¤ãƒ ã‹ã‚‰çµ¶å¯¾ã‚¹ãƒ”ãƒ¼ãƒ‰(m/s)ã‚’è¨ˆç®—ã—ã€é¦¬å ´ãƒ»ã‚³ãƒ¼ã‚¹è£œæ­£ã‚’ã‹ã‘ã‚‹ """
    if pd.isna(row.get('early_3f')):
        return np.nan
    
    raw_speed = 600.0 / row['early_3f']
    
    condition_mod = 0.0
    if row['track_type'] == "èŠ":
        if row['track_condition'] in ["é‡", "ä¸è‰¯"]: condition_mod = +0.15 
        elif row['track_condition'] == "ç¨": condition_mod = +0.05
    elif row['track_type'] == "ãƒ€ãƒ¼ãƒˆ":
        if row['track_condition'] in ["é‡", "ä¸è‰¯"]: condition_mod = -0.15 
        elif row['track_condition'] == "ç¨": condition_mod = -0.05

    course_mod = 0.0
    turf_start_dirt = [("æ±äº¬", 1600), ("ä¸­å±±", 1200), ("é˜ªç¥", 1400), ("äº¬éƒ½", 1400), ("æ–°æ½Ÿ", 1200), ("ä¸­äº¬", 1400)]
    if row['track_type'] == "ãƒ€ãƒ¼ãƒˆ" and (row['venue'], row['distance']) in turf_start_dirt:
        course_mod = -0.2

    return raw_speed + condition_mod + course_mod

def extract_jockey_target_position(past_races_df: pd.DataFrame, current_venue: str) -> float:
    if past_races_df.empty: return 7.0 
    
    is_success = (past_races_df['finish_position'] == 1) | (past_races_df['popularity'] > past_races_df['finish_position'])
    is_same_venue = past_races_df['venue'] == current_venue
    
    venue_success_races = past_races_df[is_success & is_same_venue]
    if not venue_success_races.empty:
        return float(venue_success_races.iloc[0]['first_corner_pos'])
    
    success_races = past_races_df[is_success]
    if not success_races.empty:
        return float(success_races.iloc[0]['first_corner_pos'])
        
    return float(past_races_df['first_corner_pos'].mean())

def calculate_pace_score(horse, current_dist, current_venue, current_track, total_horses):
    past_df = pd.DataFrame(horse['past_races'])
    if past_df.empty: 
        horse['condition_mod'] = 0.0
        horse['special_flag'] = ""
        return 7.0 
    
    past_df['early_speed'] = past_df.apply(calculate_early_pace_speed, axis=1)
    max_speed = past_df['early_speed'].max()
    
    speed_advantage = 0.0
    if not pd.isna(max_speed):
        speed_advantage = (16.8 - max_speed) * 3.0 

    jockey_target = extract_jockey_target_position(past_df, current_venue)
    base_position = (jockey_target * 0.6) + speed_advantage
    
    last_race = past_df.iloc[0]
    weight_modifier = (horse['current_weight'] - last_race['weight']) * 0.25
    
    base_mod = (horse['horse_number'] - 1) * 0.05 
    outside_adv_courses = [("ä¸­å±±", 1200, "ãƒ€ãƒ¼ãƒˆ"), ("æ±äº¬", 1600, "ãƒ€ãƒ¼ãƒˆ"), ("é˜ªç¥", 1400, "ãƒ€ãƒ¼ãƒˆ"), ("äº¬éƒ½", 1400, "ãƒ€ãƒ¼ãƒˆ")]
    if (current_venue, current_dist, current_track) in outside_adv_courses:
        base_mod = (total_horses - horse['horse_number']) * 0.05 - 0.4

    # å‡ºé…ã‚Œ(maru) ï¼† æ é †ã«ã‚ˆã‚‹ãƒªã‚«ãƒãƒªãƒ¼åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
    late_start_penalty = 0.0
    horse['special_flag'] = ""
    
    if last_race.get('is_late_start', False):
        late_start_penalty += 1.0 
        if last_race['first_corner_pos'] <= 5:
            is_past_outside = last_race['past_frame'] >= 5
            is_current_inside = horse['horse_number'] <= (total_horses / 2) 
            
            if is_past_outside and is_current_inside:
                late_start_penalty += 2.5
                horse['special_flag'] = "âš ï¸å‰èµ°å¤–æ ãƒªã‚«ãƒãƒ¼â†’ä»Šå›å†…æ ã§å‡ºé…ã‚Œè‡´å‘½å‚·ãƒªã‚¹ã‚¯"
            elif is_past_outside and not is_current_inside:
                late_start_penalty -= 0.5
                horse['special_flag'] = "ğŸå‡ºé…ã‚Œç™–ã‚ã‚Šã‚‚å¤–æ ã‹ã‚‰ãƒªã‚«ãƒãƒ¼è­¦æˆ’"
            elif not is_past_outside:
                horse['special_flag'] = "ğŸ”¥å‡ºé…ã‚Œã‚’å†…ã‹ã‚‰ãƒªã‚«ãƒãƒªãƒ¼ã™ã‚‹é¬¼è„š"

    final_score = base_position + weight_modifier + base_mod + late_start_penalty
    return max(1.0, min(18.0, final_score))

def format_formation(sorted_horses):
    if not sorted_horses: return ""
    leaders, chasers, mid, backs = [], [], [], []
    top_score = sorted_horses[0]['score']
    for h in sorted_horses:
        num_str = chr(9311 + h['horse_number']) 
        score = h['score']
        if score <= top_score + 1.2 and len(leaders) < 3: leaders.append(num_str)
        elif score <= top_score + 4.5: chasers.append(num_str)
        elif score <= top_score + 9.5: mid.append(num_str)
        else: backs.append(num_str)
    
    parts = []
    if leaders: parts.append(f"({''.join(leaders)})")
    if chasers: parts.append("".join(chasers))
    if mid: parts.append("".join(mid))
    if backs: parts.append("".join(backs))
    return " ".join(parts)

# ==========================================
# 2. ç«¶é¦¬ãƒ–ãƒƒã‚¯ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def fetch_real_data(race_id: str):
    url = f"https://s.keibabook.co.jp/cyuou/nouryoku_html_detail/{race_id}.html"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    try:
        response = requests.get(url, headers=headers)
        response.encoding = 'utf-8' 
        time.sleep(1) # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚å¿…ãš1ç§’å¾…æ©Ÿ
        soup = BeautifulSoup(response.text, 'html.parser')
        
        basyo_elem = soup.select_one('td.basyo')
        current_venue = basyo_elem.text.strip() if basyo_elem else "ä¸æ˜"
        if current_venue == "ä¸æ˜": return None, 1600, "", "èŠ", "å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆæœªç¢ºå®šã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚"
        
        kyori_elem = soup.select_one('span.kyori')
        course_elem = soup.select_one('span.course')
        
        current_dist = int(re.search(r'\d+', kyori_elem.text).group()) if kyori_elem else 1600
        current_track = "ãƒ€ãƒ¼ãƒˆ" if course_elem and "ãƒ€" in course_elem.text else "èŠ"

        horses_data = []
        trs = soup.select('table.noryoku tr[class^="js-umaban"]')
        if not trs:
            return None, current_dist, current_venue, current_track, "å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

        for tr in trs:
            umaban_elem = tr.select_one('td.umaban span')
            if not umaban_elem: continue
            horse_num = int(umaban_elem.text.strip())
            
            bamei_elem = tr.select_one('td.bamei span.kbamei a')
            horse_name = bamei_elem.text.strip() if bamei_elem else "ä¸æ˜"
            
            past_races = []
            current_weight = 480.0 
            
            for td in tr.select('td.zensou'):
                if not td.select_one('.kyori'): continue
                
                k_text = td.select_one('.kyori').text
                dist_m = re.search(r'\d+', k_text)
                dist = int(dist_m.group()) if dist_m else current_dist
                track = "ãƒ€ãƒ¼ãƒˆ" if "ãƒ€" in k_text else "èŠ"
                
                baba_img = td.select_one('.baba img')
                baba_cond = "è‰¯"
                if baba_img:
                    src = baba_img.get('src', '')
                    if 'ryo' in src: baba_cond = 'è‰¯'
                    elif 'yaya' in src: baba_cond = 'ç¨'
                    elif 'omo' in src: baba_cond = 'é‡'
                    elif 'huryo' in src: baba_cond = 'ä¸è‰¯'
                
                early_3f_span = td.select_one('.uzenh3')
                early_3f = float(early_3f_span.text.strip()) if early_3f_span else np.nan
                
                tuka_imgs = td.select('.tuka img')
                first_corner = 7
                is_late_start = False
                if tuka_imgs:
                    src = tuka_imgs[0].get('src', '')
                    m = re.search(r'(\d+)\.gif', src)
                    if m: first_corner = int(m.group(1))
                    if 'maru' in src: is_late_start = True 
                        
                umaban_span = td.select_one('.umaban')
                past_frame = 4
                if umaban_span:
                    frame_m = re.search(r'(\d+)æ ', umaban_span.text)
                    if frame_m: past_frame = int(frame_m.group(1))

                cyaku_span = td.select_one('span[class^="cyaku"]')
                finish_pos = int(re.search(r'\d+', cyaku_span.text).group()) if cyaku_span and re.search(r'\d+', cyaku_span.text) else 5
                
                ninki_span = td.select_one('.ninki')
                popularity = int(re.search(r'\d+', ninki_span.text).group()) if ninki_span and re.search(r'\d+', ninki_span.text) else 5
                
                negahi_spans = td.select('.negahi')
                p_venue = current_venue
                if negahi_spans:
                    v_text = negahi_spans[0].text
                    venue_map = {"æ±":"æ±äº¬", "ä¸­":"ä¸­å±±", "äº¬":"äº¬éƒ½", "é˜ª":"é˜ªç¥", "å":"ä¸­äº¬", "æ–°":"æ–°æ½Ÿ", "ç¦":"ç¦å³¶", "å°":"å°å€‰", "æœ­":"æœ­å¹Œ", "å‡½":"å‡½é¤¨"}
                    for v_key, v_val in venue_map.items():
                        if v_key in v_text:
                            p_venue = v_val
                            break
                
                batai_span = td.select_one('.batai')
                weight = float(batai_span.text.strip()) if batai_span else 480.0
                
                if len(past_races) == 0:
                    current_weight = weight
                
                past_races.append({
                    'venue': p_venue, 'track_type': track, 'distance': dist,
                    'track_condition': baba_cond, 'finish_position': finish_pos,
                    'popularity': popularity, 'early_3f': early_3f,
                    'first_corner_pos': first_corner, 'is_late_start': is_late_start,
                    'past_frame': past_frame, 'weight': weight
                })

            horses_data.append({
                'horse_number': horse_num, 'horse_name': horse_name,
                'current_weight': current_weight, 'past_races': past_races,
                'score': 0.0, 'special_flag': ""
            })

        if not horses_data: return None, 1600, "", "èŠ", "é¦¬ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        return horses_data, current_dist, current_venue, current_track, None
        
    except Exception as e:
        return None, 1600, "", "èŠ", f"ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}"

# ==========================================
# 3. ã‚¹ãƒãƒ›å¯¾å¿œUI (è¤‡æ•°ãƒ¬ãƒ¼ã‚¹é¸æŠãƒ»ä¸€æ‹¬å‡¦ç†)
# ==========================================
st.set_page_config(page_title="AIç«¶é¦¬å±•é–‹äºˆæƒ³", page_icon="ğŸ‡", layout="centered")

st.title("ğŸ‡ AIç«¶é¦¬å±•é–‹äºˆæƒ³ (ç«¶é¦¬ãƒ–ãƒƒã‚¯ç‰ˆ)")
st.markdown("ç«¶é¦¬ãƒ–ãƒƒã‚¯ã®URLã‹ã‚‰ã€Œå‰åŠ3Fã®å®Ÿæ¸¬å€¤ã€ã¨ã€Œå‡ºé…ã‚Œç”»åƒ(maru)ã€ã‚’è§£æã—ã€å…¨ãƒ¬ãƒ¼ã‚¹ã®éšŠåˆ—äºˆæƒ³ã‚’ä¸€æ‹¬å‡ºåŠ›ã—ã¾ã™ã€‚")

with st.container(border=True):
    st.subheader("âš™ï¸ ãƒ¬ãƒ¼ã‚¹è¨­å®š")
    base_url_input = st.text_input("ğŸ”— ç«¶é¦¬ãƒ–ãƒƒã‚¯ã®ãƒ¬ãƒ¼ã‚¹URL (ã©ã‚Œã‹1ãƒ¬ãƒ¼ã‚¹ã§OK)", value="https://s.keibabook.co.jp/cyuou/nouryoku_html_detail/202601040703.html")
    
    st.markdown("**ğŸ¯ äºˆæƒ³ã—ãŸã„ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰**")
    
    try:
        selected_races = st.pills("ãƒ¬ãƒ¼ã‚¹ç•ªå·", options=list(range(1, 13)), default=[11], format_func=lambda x: f"{x}R", selection_mode="multi")
    except TypeError:
        selected_races = st.multiselect("ãƒ¬ãƒ¼ã‚¹ç•ªå·", options=list(range(1, 13)), default=[11], format_func=lambda x: f"{x}R")

    if not isinstance(selected_races, list):
        if selected_races is None:
            selected_races = []
        else:
            selected_races = [selected_races]

    col1, col2 = st.columns(2)
    with col1:
        execute_btn = st.button("ğŸš€ é¸æŠãƒ¬ãƒ¼ã‚¹ã‚’äºˆæƒ³", type="primary", use_container_width=True)
    with col2:
        execute_all_btn = st.button("ğŸŒŸ å…¨12Rã‚’ä¸€æ‹¬äºˆæƒ³", type="secondary", use_container_width=True)

races_to_run = []
if execute_all_btn:
    races_to_run = list(range(1, 13))
elif execute_btn:
    if not selected_races:
        st.warning("ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    races_to_run = selected_races

if races_to_run:
    # ç«¶é¦¬ãƒ–ãƒƒã‚¯ã®URLã‹ã‚‰12æ¡ã®ãƒ¬ãƒ¼ã‚¹IDã‚’æŠ½å‡º (ä¾‹: 202601040703)
    match = re.search(r'\d{12}', base_url_input)
    if not match:
        st.error("æœ‰åŠ¹ãªç«¶é¦¬ãƒ–ãƒƒã‚¯ã®ãƒ¬ãƒ¼ã‚¹IDï¼ˆ12æ¡ã®æ•°å­—ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
        
    # å…ˆé ­10æ¡ã‚’ãƒ™ãƒ¼ã‚¹IDï¼ˆé–‹å‚¬æ—¥ãƒ»ä¼šå ´ï¼‰ã¨ã—ã¦å–å¾—
    base_id = match.group()[:10]
    
    for race_num in sorted(races_to_run):
        # ãƒ™ãƒ¼ã‚¹IDã®æœ«å°¾ã«ãƒ«ãƒ¼ãƒ—ã—ã¦ã„ã‚‹ãƒ¬ãƒ¼ã‚¹ç•ªå·(01ã€œ12)ã‚’çµåˆ
        target_race_id = f"{base_id}{race_num:02d}"
        
        st.markdown(f"### ğŸ {race_num}R")
        
        with st.spinner(f"{race_num}R ã®ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­..."):
            horses, current_dist, current_venue, current_track, error_msg = fetch_real_data(target_race_id)
            
            if error_msg:
                st.warning(f"{error_msg}")
                continue
                
            total_horses = len(horses)
            
            for horse in horses:
                horse['score'] = calculate_pace_score(horse, current_dist, current_venue, current_track, total_horses)
                
            sorted_horses = sorted(horses, key=lambda x: x['score'])
            formation_text = format_formation(sorted_horses)

            st.info(f"ğŸ“ æ¡ä»¶: **{current_venue} {current_track}{current_dist}m** ({total_horses}é ­ç«‹ã¦)")
            
            st.markdown(f"<h4 style='text-align: center; letter-spacing: 2px;'>â—€(é€²è¡Œæ–¹å‘)</h4>", unsafe_allow_html=True)
            st.markdown(f"<h3 style='text-align: center; color: #FF4B4B;'>{formation_text}</h3>", unsafe_allow_html=True)
            
            with st.expander(f"ğŸ“Š {race_num}R ã®è©³ç´°ã‚¹ã‚³ã‚¢ã¨ç‰¹è¨˜äº‹é …ã‚’è¦‹ã‚‹"):
                df_result = pd.DataFrame([{
                    "é¦¬ç•ª": h['horse_number'],
                    "é¦¬å": h['horse_name'],
                    "ã‚¹ã‚³ã‚¢": round(h['score'], 2),
                    "ç‰¹è¨˜äº‹é …": h.get('special_flag', '')
                } for h in sorted_horses])
                st.dataframe(df_result, use_container_width=True, hide_index=True)
            
            st.markdown("<br>", unsafe_allow_html=True)
